[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning Diary",
    "section": "",
    "text": "Introduction",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Sentinel-2",
    "section": "",
    "text": "Here is a short presentation discussing Sentinel-2 mission:\n\n\n\n\n\n\n\n\nFor full screen presentation of these slides, they are available here！",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Sentinel-2</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Addabbo, Pia, Mariano Focareta, Salvo Marcuccio, Claudio Votto, and\nSilvia Liberata Ullo. 2016. “Contribution of Sentinel-2 Data for\nApplications in Vegetation Monitoring.” ACTA IMEKO 5\n(2): 44. https://doi.org/10.21014/acta_imeko.v5i2.352.\n\n\nSun, Yuanheng, Qiming Qin, Huazhong Ren, Tianyuan Zhang, and Shanshan\nChen. 2020. “Red-Edge Band Vegetation Indices for Leaf Area Index\nEstimation from Sentinel-2/MSI Imagery.” IEEE Transactions on\nGeoscience and Remote Sensing 58 (2): 826–40. https://doi.org/10.1109/TGRS.2019.2940826.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "1  Getting started with remote sensing",
    "section": "",
    "text": "1.1 Summary",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with remote sensing</span>"
    ]
  },
  {
    "objectID": "week1.html#lecture",
    "href": "week1.html#lecture",
    "title": "1  Week1",
    "section": "2.1 Lecture",
    "text": "2.1 Lecture\nThis lecture in week 1 provided an introduction to the world of remote sensing, establishing the physical foundation of Earth Observation and explaining how electromagnetic waves interact with earth’s surface and atmosphere via absorption, transmission, scattering and reflection. As the atmosphere would affect satellite sensors by scattering, atmospheric correction is necessary.\nWhat I found most crucial was the framework of four resolutions (spatial, spectral, radiometric and temporal), which serves as a critical standard for evaluating sensor suitability.\nThe sensor selection is fundamentally a trade-off. For example, while MODIS has high temporal consistency (high update frequency), World Imagery offers higher spatial resolution, making it more suitable for distinguishing fine details in urban areas. In conclusion, there is no perfect sensor.\nThe choice of data must always be dictated by the specific characteristics of the research objects and the requirements of the study.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week1</span>"
    ]
  },
  {
    "objectID": "week1.html#practical",
    "href": "week1.html#practical",
    "title": "1  Week1",
    "section": "2.2 Practical",
    "text": "2.2 Practical\nSince I was unable to load data in SNAP (likely due to my MacOS compatibility issue), I wrote this part based on the practical preview page.\nIn the practical, the objective was to source data from Copernicus (Sentinel-2) and USGS (Landsat) to explore their spectral signatures.\nWe explored the concept of “Spectral Feature Space” theoretically (e.g., Red Reflectance vs. NIR scatterplots). This visualization, especially the “Tasseled Caps” distribution, showed that raw pixel values are not randomly distributed. Instead, they cluster mathematically based on physical properties like brightness (identifying urban areas), greenness (vegetation), and wetness (moisture). One significant benefit of this analysis was to see how spectral signatures distinguish land types, which is useful for automated classification. And I am going to talk about the applications of this method in literatures in the following part.\nHowever, in a complex urban environment, I questioned whether the downsampling from 10m bands to 20m would result in a loss of details. Merging distinct features like narrow streets and gardens into single pixels might create mixed signals, making the spectral signatures less accurate.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week1</span>"
    ]
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Learning Diary",
    "section": "About Me",
    "text": "About Me\nHi everyone! I am Ruijue Song. I majored in Urban Management in Central University of Finance and economy in China from 2019 to 2023.\nI am deeply interested in spatial data science, with a specific focus on using computational tools (like R and GEE) to automate complex urban analyses. So I hope CASA0023 will equip me with the technical skills to process and interpret satellite imagery, enabling me to move beyond traditional GIS mapping toward more advanced, data-driven environmental monitoring.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "3  Corrections",
    "section": "",
    "text": "3.1 Summary\nCorrections and enhancement are the two main parts of EO data pre-processing. This week, I mainly focused on two enhancements: Ratio and Texture.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Corrections</span>"
    ]
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "3  Corrections",
    "section": "",
    "text": "3.1.1 Ratio: NDVI\nRatioing exploits the contrast between spectral bands to highlight landscape features. A classic application is the Normalized Difference Vegetation Index (NDVI). This index uses the fact that healthy vegetation reflects Near-Infrared (NIR) light strongly while absorbing most Red light for photosynthesis. We could use the NDVI index to highlight areas with healthy vegetation.\n\n\n\n\n\n\n  Source: Agricolus\n\nAs shown in picture, I plotted the NDVI distribution of City of Cape Town using Landsat imagery from July 2022 in practical.\n\n\n\n\n\n\n  Normalised Difference Vegetation Index for City of Cape Town\n\nWe could get more clear results by pulling out certain areas where NDVI is greater than 0.2. It is important to note that July is winter in Cape Town, which is the rainy season. The bright yellow and green areas in the north are mostly farmlands. Crops like wheat grow rapidly during this time, resulting in high NDVI values.\n\n\n\n\n\n\n  NDVI for City of Cape Town (only showing values above 0.2)\n\nIn contrast, the southern areas (like the Cape Peninsula) show lower values. This is because the native “fynbos” vegetation consists of woody shrubs with small leaves, which naturally reflect less light than leafy crops. Also, the steep mountains cast long shadows in winter, which can lower the NDVI readings.\n\n\n3.1.2 Texture\nTexture measures the spatial relationship and structural complexity between a pixel and its neighbors. It quantifies “smoothness” (high similarity between neighbors) versus “roughness” (high contrast).\n\n\n\n\n\n\n  Texture for City of Cape Town\n\nIn the Cape Town map, the colors are mixed together rather than separated into big blocks. The yellow pixels represent small, smooth spots, such as the middle of a field, where the color doesn’t change much. The blue and green pixels represent rough areas, which are usually the edges where one object ends and another begins. This speckled look shows that the whole image is full of small details and frequent changes, rather than large, empty spaces.\n\n\n\n\n\n\nIn my map, the “speckled” mix of yellow and blue suggests the texture is very fragmented. This is likely due to the small 3x3 window size used in the analysis.\nA small 3x3 window focuses on immediate neighbors, which makes it very sensitive to fine details and edges. The benefit is that it captures precise boundaries between objects. However, a limitation is that it picks up too much “noise”, resulting in a salt-and-pepper look. This makes it harder to identify broad, continuous zones (like a whole farm) compared to what a larger window (e.g., 7x7 or 15x15) might show.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Corrections</span>"
    ]
  },
  {
    "objectID": "week1.html#summary",
    "href": "week1.html#summary",
    "title": "1  Getting started with remote sensing",
    "section": "",
    "text": "1.1.1 Lecture\nThis lecture in week 1 provided an introduction to the world of remote sensing, establishing the physical foundation of Earth Observation and explaining how electromagnetic waves interact with earth’s surface and atmosphere via absorption, transmission, scattering and reflection. As the atmosphere would affect satellite sensors by scattering, atmospheric correction is necessary.\nWhat I found most crucial was the framework of four resolutions (spatial, spectral, radiometric and temporal), which serves as a critical standard for evaluating sensor suitability.\nThe sensor selection is fundamentally a trade-off. For example, while MODIS has high temporal consistency (high update frequency), World Imagery offers higher spatial resolution, making it more suitable for distinguishing fine details in urban areas. In conclusion, there is no perfect sensor.\nThe choice of data must always be dictated by the specific characteristics of the research objects and the requirements of the study.\n\n\n1.1.2 Practical\nSince I was unable to load data in SNAP (likely due to my MacOS compatibility issue), I wrote this part based on the practical preview page.\nIn the practical, the objective was to source data from Copernicus (Sentinel-2) and USGS (Landsat) to explore their spectral signatures.\nWe explored the concept of “Spectral Feature Space” theoretically (e.g., Red Reflectance vs. NIR scatterplots). This visualization, especially the “Tasseled Caps” distribution, showed that raw pixel values are not randomly distributed. Instead, they cluster mathematically based on physical properties like brightness (identifying urban areas), greenness (vegetation), and wetness (moisture). One significant benefit of this analysis was to see how spectral signatures distinguish land types, which is useful for automated classification. And I am going to talk about the applications of this method in literatures in the following part.\nHowever, in a complex urban environment, I questioned whether the downsampling from 10m bands to 20m would result in a loss of details. Merging distinct features like narrow streets and gardens into single pixels might create mixed signals, making the spectral signatures less accurate.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with remote sensing</span>"
    ]
  },
  {
    "objectID": "week1.html#application",
    "href": "week1.html#application",
    "title": "1  Getting started with remote sensing",
    "section": "1.2 Application",
    "text": "1.2 Application\nIn this week, I mainly focus on literatures concerning applications of Sentinel-2 spectral signature on vegetation monitoring. In this area, there is a notable shift in literature from relying on traditional broad-band indices to exploiting specific narrow-band spectral signatures.\nStandard broad-band indices (such as the normalized difference vegetation index, NDVI) often saturate at high leaf area index (LAI), which is a methodological limitation that newer studies solve by using red-edge bands. Sun et al. (2020) demonstrated that vegetation indices derived specifically from Sentinel-2’s narrow red-edge bands (RE2 and RE3) yield significantly higher accuracy for LAI estimation than traditional broad-band approaches. This finding is critical as it demonstrates the theoretical framework of spectral resolution. It suggests that for detailed vegetation monitoring, having more specific spectral bands is usually more useful than simply having higher spatial resolution. The clues about plant health are hidden in these narrow bands, and we will miss them if we only focus on spatial resolution.\nConsequently, the selection of sensors in modern studies has become a strategic evaluation, not just about spatial details, but also about evaluating spectral capabilities. While older sensors like Landsat-8 are better suited for providing historical data, comparative analyses show that Sentinel-2 has distinct advantages for agriculture study and vegetation monitoring for its specific spectral configuration. Addabbo et al. (2016) argue that a series of indexes for vegetation analysis can be obtained by using Sentinel-2 near infrared spectral band images, which was previously impossible by simply using Landsat-8 data. Reflecting on the trade-off, while Landsat-8 is essential for long-term trend analysis due to its extensive archive, modern vegetation monitoring needs the higher spectral sensitivity that only newer sensors could provide.\nThese literatures reinforce the lecture’s conclusion: the best sensor is not absolute but is dictated by the primary target of the research.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with remote sensing</span>"
    ]
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "1  Getting started with remote sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nReflecting on the “spectral feature space,” I realized that remote sensing is more than just locating features, it is about understanding the biophysical composition, which is essential for making urban policy.\nFor example, using red-edge bands allows us to prove if a park is biologically healthy, rather than just checking if it looks “green” on a map. However, the problem I noticed that losing spatial detail when we prioritize spectral bands is a real challenge for complex cities. If we rely on Sentinel-2’s 20m pixels to study narrow streets, we might get mixed signals (like mixing a tree with a road), which could lead to wrong decisions in policies like managing urban heat islands. This trade-off makes me realize that for complex cities, just using SNAP (GUI) might not be enough. We have to explore using coding (like R or GEE) to handle these data challenges more flexibly or perhaps combine Sentinel-2 with higher-resolution images to get the best of both worlds.\n\n\n\n\nAddabbo, Pia, Mariano Focareta, Salvo Marcuccio, Claudio Votto, and Silvia Liberata Ullo. 2016. “Contribution of Sentinel-2 Data for Applications in Vegetation Monitoring.” ACTA IMEKO 5 (2): 44. https://doi.org/10.21014/acta_imeko.v5i2.352.\n\n\nSun, Yuanheng, Qiming Qin, Huazhong Ren, Tianyuan Zhang, and Shanshan Chen. 2020. “Red-Edge Band Vegetation Indices for Leaf Area Index Estimation from Sentinel-2/MSI Imagery.” IEEE Transactions on Geoscience and Remote Sensing 58 (2): 826–40. https://doi.org/10.1109/TGRS.2019.2940826.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with remote sensing</span>"
    ]
  },
  {
    "objectID": "week3.html#application",
    "href": "week3.html#application",
    "title": "3  Corrections",
    "section": "3.2 Application",
    "text": "3.2 Application\n\n3.2.1 Ratio: NBR\nIn week1&2, I explored how spectral indices like NDVI and red-edge ratios are crucial for monitoring vegetation health (LAI) and mitigating Urban Heat Islands. Additionally, a key application in disaster management is the Normalized Burn Ratio (NBR), which contrasts Near-Infrared (NIR) and Shortwave Infrared (SWIR) bands to identify burnt areas. High NBR values reflect healthy vegetation, while low values point to bare ground or recent burns. This website introduces how NBR can be used to identify burn severity by comparing the difference between the pre-fire and post-fire NBR (dNBR or ∆NBR).\n\n\n\n\n\n\n  Comparison of the spectral response of healthy vegetation and burned areas. Source: U.S. Forest service.\n\n\n\n3.2.2 Texture: Distinguishing Slums\nWhile spectral ratios are powerful, they are limited by the “same spectrum, different object” phenomenon. Relying solely on spectral data is insufficient for complex heterogeneous environments, such as distinguishing between formal and informal urban settlements (slums and shantytowns). Studies by Wang, Kuffer, and Pfeffer (2019) have successfully employed texture measures (GLCM) to distinguish slums from formal areas. They note that slums typically exhibit different structural patterns compared to planned housing. However, they point out a major challenge: the accuracy of the results depends heavily on the window size used. This mirrors the limitations I observed in my own practical results, where an arbitrary window size might lead to noise.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Corrections</span>"
    ]
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "3  Corrections",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nTo be honest, I found this week’s focus on enhancement much more engaging and interesting than the technical corrections process. It felt like I was finally drawing out the hidden stories in the data rather than just fixing errors. The biggest realization for me was that spectral data (ratio) isn’t the whole truth. Texture analysis fascinated me because it visualized the “roughness” of the city, picking up details that NDVI missed.\nHowever, the practical side made me realize how much my final map depended on a simple, subjective choice: the window size. It makes me slightly nervous to think about this in a real policy context: if we pick the wrong window size, we could completely misclassify a vulnerable settlement. In the future, I hope to explore more about data fusion (combining NDVI and texture), hoping that combining methods might reduce this reliance on manual trial and error.\n\n\n\n\nWang, Jiong, Monika Kuffer, and Karin Pfeffer. 2019. “The Role of Spatial Heterogeneity in Detecting Urban Slums.” Computers, Environment and Urban Systems 73 (January): 95–107. https://doi.org/10.1016/j.compenvurbsys.2018.08.007.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Corrections</span>"
    ]
  }
]